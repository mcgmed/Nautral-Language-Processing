{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQgi2FLcqPTHPvwMWygrqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcgmed/Nautral-Language-Processing/blob/main/NLTK_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou1fHBLU1ZJh"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK will display a download manager showing all available and installed resources. Here are the ones you’ll need to download for this tutorial:\n",
        "\n",
        "*   names: A list of common English names compiled by Mark Kantrowitz\n",
        "*   stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n",
        "*   state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n",
        "*   twitter_samples: A list of social media phrases posted to Twitter\n",
        "*   movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n",
        "*   averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n",
        "*   vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n",
        "*   punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists\n",
        "\n",
        "A quick way to download specific resources directly from the console is to pass a list to nltk.download():"
      ],
      "metadata": {
        "id": "cOXyHEa-4koL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download([\"names\", \"stopwords\", \"state_union\", \"twitter_samples\", \"movie_reviews\", \"averaged_perceptron_tagger\", \"vader_lexicon\", \"punkt\",])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIY3HlK85Qgo",
        "outputId": "3b818995-dd6b-404e-a4eb-215a0c4cf6a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling Data"
      ],
      "metadata": {
        "id": "Ri9ojrhTAVm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
      ],
      "metadata": {
        "id": "83ooLRhw5gr4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you build a list of individual words with the corpus’s .words() method, but you use str.isalpha() to include only the words that are made up of letters. Otherwise, your word list may end up with “words” that are only punctuation marks."
      ],
      "metadata": {
        "id": "8yQx4yxM6ZgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since all words in the stopwords list are lowercase, and those in the original list may not be, you use str.lower() to account for any discrepancies. Otherwise, you may end up with mixedCase or capitalized stop words still in your list."
      ],
      "metadata": {
        "id": "V75UHwl36x7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "words = [w for w in words if w.lower() not in stopwords]"
      ],
      "metadata": {
        "id": "xkrWHnB4535n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pprint() prints complex data structures. The normal print() function prints the entire content in a single line. This is fine if the printed content is small in length and is not a complex data structure. But the output will become difficult to read if the content is a complex data structure like a complex json or a long content."
      ],
      "metadata": {
        "id": "XX5Oc46P8utp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "text = \"\"\"For some quick analysis, creating a corpus could be overkill.\n",
        "          If all you need is a word list, there are simpler ways to achieve that goal.\"\"\"\n",
        "pprint(nltk.word_tokenize(text), width=79, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtpiS0qN8mOl",
        "outputId": "566e0802-0f46-4752-99a0-d5b892fc5467"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
            " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
            " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in nltk.word_tokenize(text) if word.isalpha()]\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyaQbqUn96Hm",
        "outputId": "9fa3d30a-00d4-4fb0-9110-4f741ff5c41c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['For',\n",
              " 'some',\n",
              " 'quick',\n",
              " 'analysis',\n",
              " 'creating',\n",
              " 'a',\n",
              " 'corpus',\n",
              " 'could',\n",
              " 'be',\n",
              " 'overkill',\n",
              " 'If',\n",
              " 'all',\n",
              " 'you',\n",
              " 'need',\n",
              " 'is',\n",
              " 'a',\n",
              " 'word',\n",
              " 'list',\n",
              " 'there',\n",
              " 'are',\n",
              " 'simpler',\n",
              " 'ways',\n",
              " 'to',\n",
              " 'achieve',\n",
              " 'that',\n",
              " 'goal']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Frequency Distributions"
      ],
      "metadata": {
        "id": "eOgAx8wIAd6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in nltk.word_tokenize(text) if word.isalpha()]\n",
        "fd = nltk.FreqDist(words)\n",
        "fd.most_common(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIMC4JWY9GVW",
        "outputId": "4ec0355c-ea6e-4bc6-f830-e41a6581c415"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2), ('For', 1), ('some', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAl3TzsZ_LY5",
        "outputId": "3cc629dc-a7a7-4218-81d4-d48af9718f8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 2, 'For': 1, 'some': 1, 'quick': 1, 'analysis': 1, 'creating': 1, 'corpus': 1, 'could': 1, 'be': 1, 'overkill': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd.tabulate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDvalyg-STJ",
        "outputId": "6237fac5-679b-4908-d633-ae158e0806f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       a      For     some    quick analysis creating   corpus    could       be overkill       If      all      you     need       is     word     list    there      are  simpler     ways       to  achieve     that     goal \n",
            "       2        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['a']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMySSTB2-Wzy",
        "outputId": "ed43d8bf-9994-447c-b6f0-0be67ece556c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['For']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNpeVeSC-br-",
        "outputId": "3b0d74a0-ffd6-42bc-aa9e-1129bb424746"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['one']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BKJNT3t-eWg",
        "outputId": "93612234-402a-4bbc-ad0e-7bdf94a224c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in fd:\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upEB2_a_-tWP",
        "outputId": "2f6be587-931a-4614-8a4f-f4291d3dfd17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "For\n",
            "some\n",
            "quick\n",
            "analysis\n",
            "creating\n",
            "corpus\n",
            "could\n",
            "be\n",
            "overkill\n",
            "If\n",
            "all\n",
            "you\n",
            "need\n",
            "is\n",
            "word\n",
            "list\n",
            "there\n",
            "are\n",
            "simpler\n",
            "ways\n",
            "to\n",
            "achieve\n",
            "that\n",
            "goal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0es6Px30ANFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Concordance and Collocations"
      ],
      "metadata": {
        "id": "ywXhR-AjAjht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before invoking .concordance(), build a new word list from the original corpus text so that all the context, even stop words, will be there:"
      ],
      "metadata": {
        "id": "iGEEO2dvALnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(nltk.corpus.state_union.words())\n",
        "text.concordance(\"america\", lines=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF7HvIIh_RTX",
        "outputId": "9cf81064-66b7-4134-b239-096e5535da63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 1079 matches:\n",
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n",
            "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
            " to make complete victory certain , America will never become a party to any pl\n",
            "nly in law and in justice . Here in America , we have labored long and hard to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since .concordance() only prints information to the console, it’s not ideal for data manipulation. To obtain a usable list that will also give you information about the location of each occurrence, use .concordance_list():"
      ],
      "metadata": {
        "id": "p1qV--b3f9tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concordance_list = text.concordance_list(\"america\", lines=2)\n",
        "for entry in concordance_list:\n",
        "  print(entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_PqrcGf_LB",
        "outputId": "5aeec727-b904-45be-c9d7-db3bd5fc55e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConcordanceLine(left=['looked', 'forward', 'and', 'moved', 'forward', '.', 'That', 'is', 'what', 'he', 'would', 'want', 'us', 'to', 'do', '.', 'That', 'is', 'what'], query='America', right=['will', 'do', '.', 'So', 'much', 'blood', 'has', 'already', 'been', 'shed', 'for', 'the', 'ideals', 'which', 'we', 'cherish', ',', 'and'], offset=242, left_print=' would want us to do . That is what', right_print='will do . So much blood has already', line=' would want us to do . That is what America will do . So much blood has already')\n",
            "ConcordanceLine(left=['even', 'a', 'momentary', 'pause', 'in', 'the', 'hard', 'fight', 'for', 'victory', '.', 'Today', ',', 'the', 'entire', 'world', 'is', 'looking', 'to'], query='America', right=['for', 'enlightened', 'leadership', 'to', 'peace', 'and', 'progress', '.', 'Such', 'a', 'leadership', 'requires', 'vision', ',', 'courage', 'and', 'tolerance', '.'], offset=294, left_print='ay , the entire world is looking to', right_print='for enlightened leadership to peace', line='ay , the entire world is looking to America for enlightened leadership to peace')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in concordance_list:\n",
        "  print(entry.line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDAqlB6YgTj9",
        "outputId": "97e87804-602e-4afd-bff2-44976668bd3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex.\"\n",
        "tokenized = nltk.word_tokenize(example)\n",
        "text = nltk.Text(tokenized)\n",
        "text.vocab() # Equivalent to fd = nltk.FreqDist(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_4Uvyn-hAij",
        "outputId": "5835f8d0-bd80-40a8-afaa-d53acee72306"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'is': 3, 'better': 3, 'than': 3, '.': 3, 'Beautiful': 1, 'ugly': 1, 'Explicit': 1, 'implicit': 1, 'Simple': 1, 'complex': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd = text.vocab()\n",
        "fd.tabulate(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvbGzaufhtPF",
        "outputId": "35782cfe-3a58-4f3e-93fb-830bcb39b453"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    is better   than \n",
            "     3      3      3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are series of words that frequently appear together in a given text. Collocations can be made up of two or more words. NLTK provides classes to handle several types of collocations:\n",
        "\n",
        "Bigrams: Frequent two-word combinations\n",
        "Trigrams: Frequent three-word combinations\n",
        "Quadgrams: Frequent four-word combinations\n",
        "\n",
        "NLTK provides specific classes for you to find collocations in your text. Following the pattern you’ve seen so far, these classes are also built from lists of words:"
      ],
      "metadata": {
        "id": "ON5nzN6Ah_Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
        "finder.ngram_fd.most_common(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1aRlHpjUWM",
        "outputId": "2a41da11-44c1-48de-c4d9-37a152e5f7f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('the', 'United', 'States'), 294), (('the', 'American', 'people'), 185)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.tabulate(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma8TgOWQjfoP",
        "outputId": "f250d507-e7fa-4ca9-d60f-ecd1730e91f0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
            "                          294                           185 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using NLTK’s Pre-Trained Sentiment Analyzer"
      ],
      "metadata": {
        "id": "WsNc76RbjmG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will continue."
      ],
      "metadata": {
        "id": "OjnDVAoykKM8"
      }
    }
  ]
}