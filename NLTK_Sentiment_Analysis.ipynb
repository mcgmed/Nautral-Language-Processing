{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRxo/3kppUkl5Up25Pbu0w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcgmed/Nautral-Language-Processing/blob/main/NLTK_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou1fHBLU1ZJh"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK will display a download manager showing all available and installed resources. Here are the ones you’ll need to download for this tutorial:\n",
        "\n",
        "*   names: A list of common English names compiled by Mark Kantrowitz\n",
        "*   stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n",
        "*   state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n",
        "*   twitter_samples: A list of social media phrases posted to Twitter\n",
        "*   movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n",
        "*   averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n",
        "*   vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n",
        "*   punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists\n",
        "\n",
        "A quick way to download specific resources directly from the console is to pass a list to nltk.download():"
      ],
      "metadata": {
        "id": "cOXyHEa-4koL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download([\"names\", \"stopwords\", \"state_union\", \"twitter_samples\", \"movie_reviews\", \"averaged_perceptron_tagger\", \"vader_lexicon\", \"punkt\",])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIY3HlK85Qgo",
        "outputId": "fd3c472a-460a-44df-d056-a7f031f27d1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling Data"
      ],
      "metadata": {
        "id": "Ri9ojrhTAVm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
      ],
      "metadata": {
        "id": "83ooLRhw5gr4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you build a list of individual words with the corpus’s .words() method, but you use str.isalpha() to include only the words that are made up of letters. Otherwise, your word list may end up with “words” that are only punctuation marks."
      ],
      "metadata": {
        "id": "8yQx4yxM6ZgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since all words in the stopwords list are lowercase, and those in the original list may not be, you use str.lower() to account for any discrepancies. Otherwise, you may end up with mixedCase or capitalized stop words still in your list."
      ],
      "metadata": {
        "id": "V75UHwl36x7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "words = [w for w in words if w.lower() not in stopwords]"
      ],
      "metadata": {
        "id": "xkrWHnB4535n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pprint() prints complex data structures. The normal print() function prints the entire content in a single line. This is fine if the printed content is small in length and is not a complex data structure. But the output will become difficult to read if the content is a complex data structure like a complex json or a long content."
      ],
      "metadata": {
        "id": "XX5Oc46P8utp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "text = \"\"\"For some quick analysis, creating a corpus could be overkill.\n",
        "          If all you need is a word list, there are simpler ways to achieve that goal.\"\"\"\n",
        "pprint(nltk.word_tokenize(text), width=79, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtpiS0qN8mOl",
        "outputId": "c6bed3f9-e486-4e03-9356-ffdcf10e8e40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
            " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
            " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in nltk.word_tokenize(text) if word.isalpha()]\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyaQbqUn96Hm",
        "outputId": "96fd5a1a-50fb-4c6e-f9e1-abdbf85fe0d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['For',\n",
              " 'some',\n",
              " 'quick',\n",
              " 'analysis',\n",
              " 'creating',\n",
              " 'a',\n",
              " 'corpus',\n",
              " 'could',\n",
              " 'be',\n",
              " 'overkill',\n",
              " 'If',\n",
              " 'all',\n",
              " 'you',\n",
              " 'need',\n",
              " 'is',\n",
              " 'a',\n",
              " 'word',\n",
              " 'list',\n",
              " 'there',\n",
              " 'are',\n",
              " 'simpler',\n",
              " 'ways',\n",
              " 'to',\n",
              " 'achieve',\n",
              " 'that',\n",
              " 'goal']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Frequency Distributions"
      ],
      "metadata": {
        "id": "eOgAx8wIAd6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in nltk.word_tokenize(text) if word.isalpha()]\n",
        "fd = nltk.FreqDist(words)\n",
        "fd.most_common(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIMC4JWY9GVW",
        "outputId": "7a1a557a-103c-4ed3-8e32-39b588583332"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2), ('For', 1), ('some', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAl3TzsZ_LY5",
        "outputId": "b13bad25-e23f-4f90-88d8-243955e98878"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 2, 'For': 1, 'some': 1, 'quick': 1, 'analysis': 1, 'creating': 1, 'corpus': 1, 'could': 1, 'be': 1, 'overkill': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd.tabulate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDvalyg-STJ",
        "outputId": "53a7fe1f-b515-4b95-a762-3e402d1e4673"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       a      For     some    quick analysis creating   corpus    could       be overkill       If      all      you     need       is     word     list    there      are  simpler     ways       to  achieve     that     goal \n",
            "       2        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1        1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['a']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMySSTB2-Wzy",
        "outputId": "a53cf8b1-fb4d-4f84-f99c-74a161b605a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['For']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNpeVeSC-br-",
        "outputId": "55467aa6-763b-4f65-f443-460e50d8aeb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd['one']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BKJNT3t-eWg",
        "outputId": "1b1fa193-c260-480a-a4ad-3e3bb2677723"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in fd:\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upEB2_a_-tWP",
        "outputId": "1a54ecc3-9ff6-433f-e067-6ee14ce402ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "For\n",
            "some\n",
            "quick\n",
            "analysis\n",
            "creating\n",
            "corpus\n",
            "could\n",
            "be\n",
            "overkill\n",
            "If\n",
            "all\n",
            "you\n",
            "need\n",
            "is\n",
            "word\n",
            "list\n",
            "there\n",
            "are\n",
            "simpler\n",
            "ways\n",
            "to\n",
            "achieve\n",
            "that\n",
            "goal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Concordance and Collocations"
      ],
      "metadata": {
        "id": "ywXhR-AjAjht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before invoking .concordance(), build a new word list from the original corpus text so that all the context, even stop words, will be there:"
      ],
      "metadata": {
        "id": "iGEEO2dvALnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(nltk.corpus.state_union.words())\n",
        "text.concordance(\"america\", lines=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF7HvIIh_RTX",
        "outputId": "f6626d3f-5ef9-42e5-b38a-f0f9b92c9b47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 1079 matches:\n",
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n",
            "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
            " to make complete victory certain , America will never become a party to any pl\n",
            "nly in law and in justice . Here in America , we have labored long and hard to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since .concordance() only prints information to the console, it’s not ideal for data manipulation. To obtain a usable list that will also give you information about the location of each occurrence, use .concordance_list():"
      ],
      "metadata": {
        "id": "p1qV--b3f9tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concordance_list = text.concordance_list(\"america\", lines=2)\n",
        "for entry in concordance_list:\n",
        "  print(entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_PqrcGf_LB",
        "outputId": "30fdb891-4735-46ad-b72b-9543ec0904b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConcordanceLine(left=['looked', 'forward', 'and', 'moved', 'forward', '.', 'That', 'is', 'what', 'he', 'would', 'want', 'us', 'to', 'do', '.', 'That', 'is', 'what'], query='America', right=['will', 'do', '.', 'So', 'much', 'blood', 'has', 'already', 'been', 'shed', 'for', 'the', 'ideals', 'which', 'we', 'cherish', ',', 'and'], offset=242, left_print=' would want us to do . That is what', right_print='will do . So much blood has already', line=' would want us to do . That is what America will do . So much blood has already')\n",
            "ConcordanceLine(left=['even', 'a', 'momentary', 'pause', 'in', 'the', 'hard', 'fight', 'for', 'victory', '.', 'Today', ',', 'the', 'entire', 'world', 'is', 'looking', 'to'], query='America', right=['for', 'enlightened', 'leadership', 'to', 'peace', 'and', 'progress', '.', 'Such', 'a', 'leadership', 'requires', 'vision', ',', 'courage', 'and', 'tolerance', '.'], offset=294, left_print='ay , the entire world is looking to', right_print='for enlightened leadership to peace', line='ay , the entire world is looking to America for enlightened leadership to peace')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in concordance_list:\n",
        "  print(entry.line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDAqlB6YgTj9",
        "outputId": "7102a6fc-cede-4213-ff95-e16d7c4111f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex.\"\n",
        "tokenized = nltk.word_tokenize(example)\n",
        "text = nltk.Text(tokenized)\n",
        "text.vocab() # Equivalent to fd = nltk.FreqDist(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_4Uvyn-hAij",
        "outputId": "308c128c-6d5d-4865-c68e-14faf18676df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'is': 3, 'better': 3, 'than': 3, '.': 3, 'Beautiful': 1, 'ugly': 1, 'Explicit': 1, 'implicit': 1, 'Simple': 1, 'complex': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd = text.vocab()\n",
        "fd.tabulate(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvbGzaufhtPF",
        "outputId": "bb97adb9-b5ba-414a-b11a-f66a948d3cd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    is better   than \n",
            "     3      3      3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are series of words that frequently appear together in a given text. Collocations can be made up of two or more words. NLTK provides classes to handle several types of collocations:\n",
        "\n",
        "Bigrams: Frequent two-word combinations\n",
        "Trigrams: Frequent three-word combinations\n",
        "Quadgrams: Frequent four-word combinations\n",
        "\n",
        "NLTK provides specific classes for you to find collocations in your text. Following the pattern you’ve seen so far, these classes are also built from lists of words:"
      ],
      "metadata": {
        "id": "ON5nzN6Ah_Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
        "finder.ngram_fd.most_common(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1aRlHpjUWM",
        "outputId": "2a179985-3da0-485b-c7e0-366cf0751846"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('the', 'United', 'States'), 294), (('the', 'American', 'people'), 185)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.tabulate(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma8TgOWQjfoP",
        "outputId": "5fcdf378-a8f3-49f0-caec-aa04a27302f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
            "                          294                           185 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using NLTK’s Pre-Trained Sentiment Analyzer"
      ],
      "metadata": {
        "id": "WsNc76RbjmG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n",
        "\n",
        "Since VADER is pretrained, you can get results more quickly than with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. It’s less accurate when rating longer, structured sentences, but it’s often a good launching point."
      ],
      "metadata": {
        "id": "OjnDVAoykKM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAAFa55_-VS4",
        "outputId": "30168a06-31e4-4550-8709-d6417eba3802"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll get back a dictionary of different scores. The negative, neutral, and positive scores are related: They all add up to 1 and can’t be negative. The compound score is calculated differently. It’s not just an average, and it can range from -1 to 1."
      ],
      "metadata": {
        "id": "JrMjt3Ky-zt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
      ],
      "metadata": {
        "id": "TicIRrcE-YbP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that you use a different corpus method, .strings(), instead of .words(). This gives you a list of raw tweets as strings."
      ],
      "metadata": {
        "id": "6xGYKWLx-_Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "def is_positive(tweet: str):\n",
        "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
        "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
        "\n",
        "shuffle(tweets)\n",
        "for tweet in tweets[:10]:\n",
        "    print(\">\", is_positive(tweet), tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEyhRBqm_YzW",
        "outputId": "c82752f0-d755-4742-97ef-c654b1b262f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> True @FC_TEAMJK3T follback :)\n",
            "> True @sehunshinedaily if it makes u feel better i never have nor will see anyone in kpop in the flesh :D\n",
            "> False RT @lenathehyena: @johnmcternan @Dungarbhan @UKLabour @Ed_Miliband it's your bloke who said he'd prefer the Tories. Did you miss that? Catc…\n",
            "> True RT @Markfergusonuk: David Cameron says he's hungrier than he was five years ago. So are all of the people reliant on food banks...\n",
            "> False Farage never heard of pearl harbour?  #AskNigelFarage\n",
            "> False RT @A_Liberty_Rebel: Farage is right. The EU’s protectionist CAP itself creates poverty among would-be exporters from Africa to Europe. #bb…\n",
            "> False RT @timothy_stanley: #Farage's preference for reversing the smoking ban is a rare example of a conservatism that actually seeks to turn the…\n",
            "> False UK audience grills Cameron, Miliband, Clegg in Question Time 'debate' http//t.co/sev4g8qh3c\n",
            "> True RT @AndrewSparrow: On best PM, Cameron ahead of Miliband, 48% to 34% - http//t.co/Pu8rOdGS1a\n",
            "> False RT @IrvineWelsh: Miliband saying to Lab activists in Eng, 'if it's close (looks it could be) then we'll stand aside &amp; let Tories rule rathe…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(nltk.corpus.movie_reviews.fileids(categories=[\"pos\"]), compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv2Cr2v0BZtS",
        "outputId": "4216513e-f1db-4333-ab2d-da69da6d688e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pos/cv000_29590.txt', 'pos/cv001_18431.txt', 'pos/cv002_15918.txt',\n",
            " 'pos/cv003_11664.txt', 'pos/cv004_11636.txt', 'pos/cv005_29443.txt',\n",
            " 'pos/cv006_15448.txt', 'pos/cv007_4968.txt', 'pos/cv008_29435.txt',\n",
            " 'pos/cv009_29592.txt', 'pos/cv010_29198.txt', 'pos/cv011_12166.txt',\n",
            " 'pos/cv012_29576.txt', 'pos/cv013_10159.txt', 'pos/cv014_13924.txt',\n",
            " 'pos/cv015_29439.txt', 'pos/cv016_4659.txt', 'pos/cv017_22464.txt',\n",
            " 'pos/cv018_20137.txt', 'pos/cv019_14482.txt', 'pos/cv020_8825.txt',\n",
            " 'pos/cv021_15838.txt', 'pos/cv022_12864.txt', 'pos/cv023_12672.txt',\n",
            " 'pos/cv024_6778.txt', 'pos/cv025_3108.txt', 'pos/cv026_29325.txt',\n",
            " 'pos/cv027_25219.txt', 'pos/cv028_26746.txt', 'pos/cv029_18643.txt',\n",
            " 'pos/cv030_21593.txt', 'pos/cv031_18452.txt', 'pos/cv032_22550.txt',\n",
            " 'pos/cv033_24444.txt', 'pos/cv034_29647.txt', 'pos/cv035_3954.txt',\n",
            " 'pos/cv036_16831.txt', 'pos/cv037_18510.txt', 'pos/cv038_9749.txt',\n",
            " 'pos/cv039_6170.txt', 'pos/cv040_8276.txt', 'pos/cv041_21113.txt',\n",
            " 'pos/cv042_10982.txt', 'pos/cv043_15013.txt', 'pos/cv044_16969.txt',\n",
            " 'pos/cv045_23923.txt', 'pos/cv046_10188.txt', 'pos/cv047_1754.txt',\n",
            " 'pos/cv048_16828.txt', 'pos/cv049_20471.txt', 'pos/cv050_11175.txt',\n",
            " 'pos/cv051_10306.txt', 'pos/cv052_29378.txt', 'pos/cv053_21822.txt',\n",
            " 'pos/cv054_4230.txt', 'pos/cv055_8338.txt', 'pos/cv056_13133.txt',\n",
            " 'pos/cv057_7453.txt', 'pos/cv058_8025.txt', 'pos/cv059_28885.txt',\n",
            " 'pos/cv060_10844.txt', 'pos/cv061_8837.txt', 'pos/cv062_23115.txt',\n",
            " 'pos/cv063_28997.txt', 'pos/cv064_24576.txt', 'pos/cv065_15248.txt',\n",
            " 'pos/cv066_10821.txt', 'pos/cv067_19774.txt', 'pos/cv068_13400.txt',\n",
            " 'pos/cv069_10801.txt', 'pos/cv070_12289.txt', 'pos/cv071_12095.txt',\n",
            " 'pos/cv072_6169.txt', 'pos/cv073_21785.txt', 'pos/cv074_6875.txt',\n",
            " 'pos/cv075_6500.txt', 'pos/cv076_24945.txt', 'pos/cv077_22138.txt',\n",
            " 'pos/cv078_14730.txt', 'pos/cv079_11933.txt', 'pos/cv080_13465.txt',\n",
            " 'pos/cv081_16582.txt', 'pos/cv082_11080.txt', 'pos/cv083_24234.txt',\n",
            " 'pos/cv084_13566.txt', 'pos/cv085_1381.txt', 'pos/cv086_18371.txt',\n",
            " 'pos/cv087_1989.txt', 'pos/cv088_24113.txt', 'pos/cv089_11418.txt',\n",
            " 'pos/cv090_0042.txt', 'pos/cv091_7400.txt', 'pos/cv092_28017.txt',\n",
            " 'pos/cv093_13951.txt', 'pos/cv094_27889.txt', 'pos/cv095_28892.txt',\n",
            " 'pos/cv096_11474.txt', 'pos/cv097_24970.txt', 'pos/cv098_15435.txt',\n",
            " 'pos/cv099_10534.txt', 'pos/cv100_11528.txt', 'pos/cv101_10175.txt',\n",
            " 'pos/cv102_7846.txt', 'pos/cv103_11021.txt', 'pos/cv104_18134.txt',\n",
            " 'pos/cv105_17990.txt', 'pos/cv106_16807.txt', 'pos/cv107_24319.txt',\n",
            " 'pos/cv108_15571.txt', 'pos/cv109_21172.txt', 'pos/cv110_27788.txt',\n",
            " 'pos/cv111_11473.txt', 'pos/cv112_11193.txt', 'pos/cv113_23102.txt',\n",
            " 'pos/cv114_18398.txt', 'pos/cv115_25396.txt', 'pos/cv116_28942.txt',\n",
            " 'pos/cv117_24295.txt', 'pos/cv118_28980.txt', 'pos/cv119_9867.txt',\n",
            " 'pos/cv120_4111.txt', 'pos/cv121_17302.txt', 'pos/cv122_7392.txt',\n",
            " 'pos/cv123_11182.txt', 'pos/cv124_4122.txt', 'pos/cv125_9391.txt',\n",
            " 'pos/cv126_28971.txt', 'pos/cv127_14711.txt', 'pos/cv128_29627.txt',\n",
            " 'pos/cv129_16741.txt', 'pos/cv130_17083.txt', 'pos/cv131_10713.txt',\n",
            " 'pos/cv132_5618.txt', 'pos/cv133_16336.txt', 'pos/cv134_22246.txt',\n",
            " 'pos/cv135_11603.txt', 'pos/cv136_11505.txt', 'pos/cv137_15422.txt',\n",
            " 'pos/cv138_12721.txt', 'pos/cv139_12873.txt', 'pos/cv140_7479.txt',\n",
            " 'pos/cv141_15686.txt', 'pos/cv142_22516.txt', 'pos/cv143_19666.txt',\n",
            " 'pos/cv144_5007.txt', 'pos/cv145_11472.txt', 'pos/cv146_18458.txt',\n",
            " 'pos/cv147_21193.txt', 'pos/cv148_16345.txt', 'pos/cv149_15670.txt',\n",
            " 'pos/cv150_12916.txt', 'pos/cv151_15771.txt', 'pos/cv152_8736.txt',\n",
            " 'pos/cv153_10779.txt', 'pos/cv154_9328.txt', 'pos/cv155_7308.txt',\n",
            " 'pos/cv156_10481.txt', 'pos/cv157_29372.txt', 'pos/cv158_10390.txt',\n",
            " 'pos/cv159_29505.txt', 'pos/cv160_10362.txt', 'pos/cv161_11425.txt',\n",
            " 'pos/cv162_10424.txt', 'pos/cv163_10052.txt', 'pos/cv164_22447.txt',\n",
            " 'pos/cv165_22619.txt', 'pos/cv166_11052.txt', 'pos/cv167_16376.txt',\n",
            " 'pos/cv168_7050.txt', 'pos/cv169_23778.txt', 'pos/cv170_3006.txt',\n",
            " 'pos/cv171_13537.txt', 'pos/cv172_11131.txt', 'pos/cv173_4471.txt',\n",
            " 'pos/cv174_9659.txt', 'pos/cv175_6964.txt', 'pos/cv176_12857.txt',\n",
            " 'pos/cv177_10367.txt', 'pos/cv178_12972.txt', 'pos/cv179_9228.txt',\n",
            " 'pos/cv180_16113.txt', 'pos/cv181_14401.txt', 'pos/cv182_7281.txt',\n",
            " 'pos/cv183_18612.txt', 'pos/cv184_2673.txt', 'pos/cv185_28654.txt',\n",
            " 'pos/cv186_2269.txt', 'pos/cv187_12829.txt', 'pos/cv188_19226.txt',\n",
            " 'pos/cv189_22934.txt', 'pos/cv190_27052.txt', 'pos/cv191_29719.txt',\n",
            " 'pos/cv192_14395.txt', 'pos/cv193_5416.txt', 'pos/cv194_12079.txt',\n",
            " 'pos/cv195_14528.txt', 'pos/cv196_29027.txt', 'pos/cv197_29328.txt',\n",
            " 'pos/cv198_18180.txt', 'pos/cv199_9629.txt', 'pos/cv200_2915.txt',\n",
            " 'pos/cv201_6997.txt', 'pos/cv202_10654.txt', 'pos/cv203_17986.txt',\n",
            " 'pos/cv204_8451.txt', 'pos/cv205_9457.txt', 'pos/cv206_14293.txt',\n",
            " 'pos/cv207_29284.txt', 'pos/cv208_9020.txt', 'pos/cv209_29118.txt',\n",
            " 'pos/cv210_9312.txt', 'pos/cv211_9953.txt', 'pos/cv212_10027.txt',\n",
            " 'pos/cv213_18934.txt', 'pos/cv214_12294.txt', 'pos/cv215_22240.txt',\n",
            " 'pos/cv216_18738.txt', 'pos/cv217_28842.txt', 'pos/cv218_24352.txt',\n",
            " 'pos/cv219_18626.txt', 'pos/cv220_29059.txt', 'pos/cv221_2695.txt',\n",
            " 'pos/cv222_17395.txt', 'pos/cv223_29066.txt', 'pos/cv224_17661.txt',\n",
            " 'pos/cv225_29224.txt', 'pos/cv226_2618.txt', 'pos/cv227_24215.txt',\n",
            " 'pos/cv228_5806.txt', 'pos/cv229_13611.txt', 'pos/cv230_7428.txt',\n",
            " 'pos/cv231_10425.txt', 'pos/cv232_14991.txt', 'pos/cv233_15964.txt',\n",
            " 'pos/cv234_20643.txt', 'pos/cv235_10217.txt', 'pos/cv236_11565.txt',\n",
            " 'pos/cv237_19221.txt', 'pos/cv238_12931.txt', 'pos/cv239_3385.txt',\n",
            " 'pos/cv240_14336.txt', 'pos/cv241_23130.txt', 'pos/cv242_10638.txt',\n",
            " 'pos/cv243_20728.txt', 'pos/cv244_21649.txt', 'pos/cv245_8569.txt',\n",
            " 'pos/cv246_28807.txt', 'pos/cv247_13142.txt', 'pos/cv248_13987.txt',\n",
            " 'pos/cv249_11640.txt', 'pos/cv250_25616.txt', 'pos/cv251_22636.txt',\n",
            " 'pos/cv252_23779.txt', 'pos/cv253_10077.txt', 'pos/cv254_6027.txt',\n",
            " 'pos/cv255_13683.txt', 'pos/cv256_14740.txt', 'pos/cv257_10975.txt',\n",
            " 'pos/cv258_5792.txt', 'pos/cv259_10934.txt', 'pos/cv260_13959.txt',\n",
            " 'pos/cv261_10954.txt', 'pos/cv262_12649.txt', 'pos/cv263_19259.txt',\n",
            " 'pos/cv264_12801.txt', 'pos/cv265_10814.txt', 'pos/cv266_25779.txt',\n",
            " 'pos/cv267_14952.txt', 'pos/cv268_18834.txt', 'pos/cv269_21732.txt',\n",
            " 'pos/cv270_6079.txt', 'pos/cv271_13837.txt', 'pos/cv272_18974.txt',\n",
            " 'pos/cv273_29112.txt', 'pos/cv274_25253.txt', 'pos/cv275_28887.txt',\n",
            " 'pos/cv276_15684.txt', 'pos/cv277_19091.txt', 'pos/cv278_13041.txt',\n",
            " 'pos/cv279_18329.txt', 'pos/cv280_8267.txt', 'pos/cv281_23253.txt',\n",
            " 'pos/cv282_6653.txt', 'pos/cv283_11055.txt', 'pos/cv284_19119.txt',\n",
            " 'pos/cv285_16494.txt', 'pos/cv286_25050.txt', 'pos/cv287_15900.txt',\n",
            " 'pos/cv288_18791.txt', 'pos/cv289_6463.txt', 'pos/cv290_11084.txt',\n",
            " 'pos/cv291_26635.txt', 'pos/cv292_7282.txt', 'pos/cv293_29856.txt',\n",
            " 'pos/cv294_11684.txt', 'pos/cv295_15570.txt', 'pos/cv296_12251.txt',\n",
            " 'pos/cv297_10047.txt', 'pos/cv298_23111.txt', 'pos/cv299_16214.txt',\n",
            " 'pos/cv300_22284.txt', 'pos/cv301_12146.txt', 'pos/cv302_25649.txt',\n",
            " 'pos/cv303_27520.txt', 'pos/cv304_28706.txt', 'pos/cv305_9946.txt',\n",
            " 'pos/cv306_10364.txt', 'pos/cv307_25270.txt', 'pos/cv308_5016.txt',\n",
            " 'pos/cv309_22571.txt', 'pos/cv310_13091.txt', 'pos/cv311_16002.txt',\n",
            " 'pos/cv312_29377.txt', 'pos/cv313_18198.txt', 'pos/cv314_14422.txt',\n",
            " 'pos/cv315_11629.txt', 'pos/cv316_6370.txt', 'pos/cv317_24049.txt',\n",
            " 'pos/cv318_10493.txt', 'pos/cv319_14727.txt', 'pos/cv320_9530.txt',\n",
            " 'pos/cv321_12843.txt', 'pos/cv322_20318.txt', 'pos/cv323_29805.txt',\n",
            " 'pos/cv324_7082.txt', 'pos/cv325_16629.txt', 'pos/cv326_13295.txt',\n",
            " 'pos/cv327_20292.txt', 'pos/cv328_10373.txt', 'pos/cv329_29370.txt',\n",
            " 'pos/cv330_29809.txt', 'pos/cv331_8273.txt', 'pos/cv332_16307.txt',\n",
            " 'pos/cv333_8916.txt', 'pos/cv334_10001.txt', 'pos/cv335_14665.txt',\n",
            " 'pos/cv336_10143.txt', 'pos/cv337_29181.txt', 'pos/cv338_8821.txt',\n",
            " 'pos/cv339_21119.txt', 'pos/cv340_13287.txt', 'pos/cv341_24430.txt',\n",
            " 'pos/cv342_19456.txt', 'pos/cv343_10368.txt', 'pos/cv344_5312.txt',\n",
            " 'pos/cv345_9954.txt', 'pos/cv346_18168.txt', 'pos/cv347_13194.txt',\n",
            " 'pos/cv348_18176.txt', 'pos/cv349_13507.txt', 'pos/cv350_20670.txt',\n",
            " 'pos/cv351_15458.txt', 'pos/cv352_5524.txt', 'pos/cv353_18159.txt',\n",
            " 'pos/cv354_8132.txt', 'pos/cv355_16413.txt', 'pos/cv356_25163.txt',\n",
            " 'pos/cv357_13156.txt', 'pos/cv358_10691.txt', 'pos/cv359_6647.txt',\n",
            " 'pos/cv360_8398.txt', 'pos/cv361_28944.txt', 'pos/cv362_15341.txt',\n",
            " 'pos/cv363_29332.txt', 'pos/cv364_12901.txt', 'pos/cv365_11576.txt',\n",
            " 'pos/cv366_10221.txt', 'pos/cv367_22792.txt', 'pos/cv368_10466.txt',\n",
            " 'pos/cv369_12886.txt', 'pos/cv370_5221.txt', 'pos/cv371_7630.txt',\n",
            " 'pos/cv372_6552.txt', 'pos/cv373_20404.txt', 'pos/cv374_25436.txt',\n",
            " 'pos/cv375_9929.txt', 'pos/cv376_19435.txt', 'pos/cv377_7946.txt',\n",
            " 'pos/cv378_20629.txt', 'pos/cv379_21963.txt', 'pos/cv380_7574.txt',\n",
            " 'pos/cv381_20172.txt', 'pos/cv382_7897.txt', 'pos/cv383_13116.txt',\n",
            " 'pos/cv384_17140.txt', 'pos/cv385_29741.txt', 'pos/cv386_10080.txt',\n",
            " 'pos/cv387_11507.txt', 'pos/cv388_12009.txt', 'pos/cv389_9369.txt',\n",
            " 'pos/cv390_11345.txt', 'pos/cv391_10802.txt', 'pos/cv392_11458.txt',\n",
            " 'pos/cv393_29327.txt', 'pos/cv394_5137.txt', 'pos/cv395_10849.txt',\n",
            " 'pos/cv396_17989.txt', 'pos/cv397_29023.txt', 'pos/cv398_15537.txt',\n",
            " 'pos/cv399_2877.txt', 'pos/cv400_19220.txt', 'pos/cv401_12605.txt',\n",
            " 'pos/cv402_14425.txt', 'pos/cv403_6621.txt', 'pos/cv404_20315.txt',\n",
            " 'pos/cv405_20399.txt', 'pos/cv406_21020.txt', 'pos/cv407_22637.txt',\n",
            " 'pos/cv408_5297.txt', 'pos/cv409_29786.txt', 'pos/cv410_24266.txt',\n",
            " 'pos/cv411_15007.txt', 'pos/cv412_24095.txt', 'pos/cv413_7398.txt',\n",
            " 'pos/cv414_10518.txt', 'pos/cv415_22517.txt', 'pos/cv416_11136.txt',\n",
            " 'pos/cv417_13115.txt', 'pos/cv418_14774.txt', 'pos/cv419_13394.txt',\n",
            " 'pos/cv420_28795.txt', 'pos/cv421_9709.txt', 'pos/cv422_9381.txt',\n",
            " 'pos/cv423_11155.txt', 'pos/cv424_8831.txt', 'pos/cv425_8250.txt',\n",
            " 'pos/cv426_10421.txt', 'pos/cv427_10825.txt', 'pos/cv428_11347.txt',\n",
            " 'pos/cv429_7439.txt', 'pos/cv430_17351.txt', 'pos/cv431_7085.txt',\n",
            " 'pos/cv432_14224.txt', 'pos/cv433_10144.txt', 'pos/cv434_5793.txt',\n",
            " 'pos/cv435_23110.txt', 'pos/cv436_19179.txt', 'pos/cv437_22849.txt',\n",
            " 'pos/cv438_8043.txt', 'pos/cv439_15970.txt', 'pos/cv440_15243.txt',\n",
            " 'pos/cv441_13711.txt', 'pos/cv442_13846.txt', 'pos/cv443_21118.txt',\n",
            " 'pos/cv444_9974.txt', 'pos/cv445_25882.txt', 'pos/cv446_11353.txt',\n",
            " 'pos/cv447_27332.txt', 'pos/cv448_14695.txt', 'pos/cv449_8785.txt',\n",
            " 'pos/cv450_7890.txt', 'pos/cv451_10690.txt', 'pos/cv452_5088.txt',\n",
            " 'pos/cv453_10379.txt', 'pos/cv454_2053.txt', 'pos/cv455_29000.txt',\n",
            " 'pos/cv456_18985.txt', 'pos/cv457_18453.txt', 'pos/cv458_8604.txt',\n",
            " 'pos/cv459_20319.txt', 'pos/cv460_10842.txt', 'pos/cv461_19600.txt',\n",
            " 'pos/cv462_19350.txt', 'pos/cv463_10343.txt', 'pos/cv464_15650.txt',\n",
            " 'pos/cv465_22431.txt', 'pos/cv466_18722.txt', 'pos/cv467_25773.txt',\n",
            " 'pos/cv468_15228.txt', 'pos/cv469_20630.txt', 'pos/cv470_15952.txt',\n",
            " 'pos/cv471_16858.txt', 'pos/cv472_29280.txt', 'pos/cv473_7367.txt',\n",
            " 'pos/cv474_10209.txt', 'pos/cv475_21692.txt', 'pos/cv476_16856.txt',\n",
            " 'pos/cv477_22479.txt', 'pos/cv478_14309.txt', 'pos/cv479_5649.txt',\n",
            " 'pos/cv480_19817.txt', 'pos/cv481_7436.txt', 'pos/cv482_10580.txt',\n",
            " 'pos/cv483_16378.txt', 'pos/cv484_25054.txt', 'pos/cv485_26649.txt',\n",
            " 'pos/cv486_9799.txt', 'pos/cv487_10446.txt', 'pos/cv488_19856.txt',\n",
            " 'pos/cv489_17906.txt', 'pos/cv490_17872.txt', 'pos/cv491_12145.txt',\n",
            " 'pos/cv492_18271.txt', 'pos/cv493_12839.txt', 'pos/cv494_17389.txt',\n",
            " 'pos/cv495_14518.txt', 'pos/cv496_10530.txt', 'pos/cv497_26980.txt',\n",
            " 'pos/cv498_8832.txt', 'pos/cv499_10658.txt', 'pos/cv500_10251.txt',\n",
            " 'pos/cv501_11657.txt', 'pos/cv502_10406.txt', 'pos/cv503_10558.txt',\n",
            " 'pos/cv504_29243.txt', 'pos/cv505_12090.txt', 'pos/cv506_15956.txt',\n",
            " 'pos/cv507_9220.txt', 'pos/cv508_16006.txt', 'pos/cv509_15888.txt',\n",
            " 'pos/cv510_23360.txt', 'pos/cv511_10132.txt', 'pos/cv512_15965.txt',\n",
            " 'pos/cv513_6923.txt', 'pos/cv514_11187.txt', 'pos/cv515_17069.txt',\n",
            " 'pos/cv516_11172.txt', 'pos/cv517_19219.txt', 'pos/cv518_13331.txt',\n",
            " 'pos/cv519_14661.txt', 'pos/cv520_12295.txt', 'pos/cv521_15828.txt',\n",
            " 'pos/cv522_5583.txt', 'pos/cv523_16615.txt', 'pos/cv524_23627.txt',\n",
            " 'pos/cv525_16122.txt', 'pos/cv526_12083.txt', 'pos/cv527_10123.txt',\n",
            " 'pos/cv528_10822.txt', 'pos/cv529_10420.txt', 'pos/cv530_16212.txt',\n",
            " 'pos/cv531_26486.txt', 'pos/cv532_6522.txt', 'pos/cv533_9821.txt',\n",
            " 'pos/cv534_14083.txt', 'pos/cv535_19728.txt', 'pos/cv536_27134.txt',\n",
            " 'pos/cv537_12370.txt', 'pos/cv538_28667.txt', 'pos/cv539_20347.txt',\n",
            " 'pos/cv540_3421.txt', 'pos/cv541_28835.txt', 'pos/cv542_18980.txt',\n",
            " 'pos/cv543_5045.txt', 'pos/cv544_5108.txt', 'pos/cv545_12014.txt',\n",
            " 'pos/cv546_11767.txt', 'pos/cv547_16324.txt', 'pos/cv548_17731.txt',\n",
            " 'pos/cv549_21443.txt', 'pos/cv550_22211.txt', 'pos/cv551_10565.txt',\n",
            " 'pos/cv552_10016.txt', 'pos/cv553_26915.txt', 'pos/cv554_13151.txt',\n",
            " 'pos/cv555_23922.txt', 'pos/cv556_14808.txt', 'pos/cv557_11449.txt',\n",
            " 'pos/cv558_29507.txt', 'pos/cv559_0050.txt', 'pos/cv560_17175.txt',\n",
            " 'pos/cv561_9201.txt', 'pos/cv562_10359.txt', 'pos/cv563_17257.txt',\n",
            " 'pos/cv564_11110.txt', 'pos/cv565_29572.txt', 'pos/cv566_8581.txt',\n",
            " 'pos/cv567_29611.txt', 'pos/cv568_15638.txt', 'pos/cv569_26381.txt',\n",
            " 'pos/cv570_29082.txt', 'pos/cv571_29366.txt', 'pos/cv572_18657.txt',\n",
            " 'pos/cv573_29525.txt', 'pos/cv574_22156.txt', 'pos/cv575_21150.txt',\n",
            " 'pos/cv576_14094.txt', 'pos/cv577_28549.txt', 'pos/cv578_15094.txt',\n",
            " 'pos/cv579_11605.txt', 'pos/cv580_14064.txt', 'pos/cv581_19381.txt',\n",
            " 'pos/cv582_6559.txt', 'pos/cv583_29692.txt', 'pos/cv584_29722.txt',\n",
            " 'pos/cv585_22496.txt', 'pos/cv586_7543.txt', 'pos/cv587_19162.txt',\n",
            " 'pos/cv588_13008.txt', 'pos/cv589_12064.txt', 'pos/cv590_19290.txt',\n",
            " 'pos/cv591_23640.txt', 'pos/cv592_22315.txt', 'pos/cv593_10987.txt',\n",
            " 'pos/cv594_11039.txt', 'pos/cv595_25335.txt', 'pos/cv596_28311.txt',\n",
            " 'pos/cv597_26360.txt', 'pos/cv598_16452.txt', 'pos/cv599_20988.txt',\n",
            " 'pos/cv600_23878.txt', 'pos/cv601_23453.txt', 'pos/cv602_8300.txt',\n",
            " 'pos/cv603_17694.txt', 'pos/cv604_2230.txt', 'pos/cv605_11800.txt',\n",
            " 'pos/cv606_15985.txt', 'pos/cv607_7717.txt', 'pos/cv608_23231.txt',\n",
            " 'pos/cv609_23877.txt', 'pos/cv610_2287.txt', 'pos/cv611_21120.txt',\n",
            " 'pos/cv612_5461.txt', 'pos/cv613_21796.txt', 'pos/cv614_10626.txt',\n",
            " 'pos/cv615_14182.txt', 'pos/cv616_29319.txt', 'pos/cv617_9322.txt',\n",
            " 'pos/cv618_8974.txt', 'pos/cv619_12462.txt', 'pos/cv620_24265.txt',\n",
            " 'pos/cv621_14368.txt', 'pos/cv622_8147.txt', 'pos/cv623_15356.txt',\n",
            " 'pos/cv624_10744.txt', 'pos/cv625_12440.txt', 'pos/cv626_7410.txt',\n",
            " 'pos/cv627_11620.txt', 'pos/cv628_19325.txt', 'pos/cv629_14909.txt',\n",
            " 'pos/cv630_10057.txt', 'pos/cv631_4967.txt', 'pos/cv632_9610.txt',\n",
            " 'pos/cv633_29837.txt', 'pos/cv634_11101.txt', 'pos/cv635_10022.txt',\n",
            " 'pos/cv636_15279.txt', 'pos/cv637_1250.txt', 'pos/cv638_2953.txt',\n",
            " 'pos/cv639_10308.txt', 'pos/cv640_5378.txt', 'pos/cv641_12349.txt',\n",
            " 'pos/cv642_29867.txt', 'pos/cv643_29349.txt', 'pos/cv644_17154.txt',\n",
            " 'pos/cv645_15668.txt', 'pos/cv646_15065.txt', 'pos/cv647_13691.txt',\n",
            " 'pos/cv648_15792.txt', 'pos/cv649_12735.txt', 'pos/cv650_14340.txt',\n",
            " 'pos/cv651_10492.txt', 'pos/cv652_13972.txt', 'pos/cv653_19583.txt',\n",
            " 'pos/cv654_18246.txt', 'pos/cv655_11154.txt', 'pos/cv656_24201.txt',\n",
            " 'pos/cv657_24513.txt', 'pos/cv658_10532.txt', 'pos/cv659_19944.txt',\n",
            " 'pos/cv660_21893.txt', 'pos/cv661_2450.txt', 'pos/cv662_13320.txt',\n",
            " 'pos/cv663_13019.txt', 'pos/cv664_4389.txt', 'pos/cv665_29538.txt',\n",
            " 'pos/cv666_18963.txt', 'pos/cv667_18467.txt', 'pos/cv668_17604.txt',\n",
            " 'pos/cv669_22995.txt', 'pos/cv670_25826.txt', 'pos/cv671_5054.txt',\n",
            " 'pos/cv672_28083.txt', 'pos/cv673_24714.txt', 'pos/cv674_10732.txt',\n",
            " 'pos/cv675_21588.txt', 'pos/cv676_21090.txt', 'pos/cv677_17715.txt',\n",
            " 'pos/cv678_13419.txt', 'pos/cv679_28559.txt', 'pos/cv680_10160.txt',\n",
            " 'pos/cv681_9692.txt', 'pos/cv682_16139.txt', 'pos/cv683_12167.txt',\n",
            " 'pos/cv684_11798.txt', 'pos/cv685_5947.txt', 'pos/cv686_13900.txt',\n",
            " 'pos/cv687_21100.txt', 'pos/cv688_7368.txt', 'pos/cv689_12587.txt',\n",
            " 'pos/cv690_5619.txt', 'pos/cv691_5043.txt', 'pos/cv692_15451.txt',\n",
            " 'pos/cv693_18063.txt', 'pos/cv694_4876.txt', 'pos/cv695_21108.txt',\n",
            " 'pos/cv696_29740.txt', 'pos/cv697_11162.txt', 'pos/cv698_15253.txt',\n",
            " 'pos/cv699_7223.txt', 'pos/cv700_21947.txt', 'pos/cv701_14252.txt',\n",
            " 'pos/cv702_11500.txt', 'pos/cv703_16143.txt', 'pos/cv704_15969.txt',\n",
            " 'pos/cv705_11059.txt', 'pos/cv706_24716.txt', 'pos/cv707_10678.txt',\n",
            " 'pos/cv708_28729.txt', 'pos/cv709_10529.txt', 'pos/cv710_22577.txt',\n",
            " 'pos/cv711_11665.txt', 'pos/cv712_22920.txt', 'pos/cv713_29155.txt',\n",
            " 'pos/cv714_18502.txt', 'pos/cv715_18179.txt', 'pos/cv716_10514.txt',\n",
            " 'pos/cv717_15953.txt', 'pos/cv718_11434.txt', 'pos/cv719_5713.txt',\n",
            " 'pos/cv720_5389.txt', 'pos/cv721_29121.txt', 'pos/cv722_7110.txt',\n",
            " 'pos/cv723_8648.txt', 'pos/cv724_13681.txt', 'pos/cv725_10103.txt',\n",
            " 'pos/cv726_4719.txt', 'pos/cv727_4978.txt', 'pos/cv728_16133.txt',\n",
            " 'pos/cv729_10154.txt', 'pos/cv730_10279.txt', 'pos/cv731_4136.txt',\n",
            " 'pos/cv732_12245.txt', 'pos/cv733_9839.txt', 'pos/cv734_21568.txt',\n",
            " 'pos/cv735_18801.txt', 'pos/cv736_23670.txt', 'pos/cv737_28907.txt',\n",
            " 'pos/cv738_10116.txt', 'pos/cv739_11209.txt', 'pos/cv740_12445.txt',\n",
            " 'pos/cv741_11890.txt', 'pos/cv742_7751.txt', 'pos/cv743_15449.txt',\n",
            " 'pos/cv744_10038.txt', 'pos/cv745_12773.txt', 'pos/cv746_10147.txt',\n",
            " 'pos/cv747_16556.txt', 'pos/cv748_12786.txt', 'pos/cv749_17765.txt',\n",
            " 'pos/cv750_10180.txt', 'pos/cv751_15719.txt', 'pos/cv752_24155.txt',\n",
            " 'pos/cv753_10875.txt', 'pos/cv754_7216.txt', 'pos/cv755_23616.txt',\n",
            " 'pos/cv756_22540.txt', 'pos/cv757_10189.txt', 'pos/cv758_9671.txt',\n",
            " 'pos/cv759_13522.txt', 'pos/cv760_8597.txt', 'pos/cv761_12620.txt',\n",
            " 'pos/cv762_13927.txt', 'pos/cv763_14729.txt', 'pos/cv764_11739.txt',\n",
            " 'pos/cv765_19037.txt', 'pos/cv766_7540.txt', 'pos/cv767_14062.txt',\n",
            " 'pos/cv768_11751.txt', 'pos/cv769_8123.txt', 'pos/cv770_10451.txt',\n",
            " 'pos/cv771_28665.txt', 'pos/cv772_12119.txt', 'pos/cv773_18817.txt',\n",
            " 'pos/cv774_13845.txt', 'pos/cv775_16237.txt', 'pos/cv776_20529.txt',\n",
            " 'pos/cv777_10094.txt', 'pos/cv778_17330.txt', 'pos/cv779_17881.txt',\n",
            " 'pos/cv780_7984.txt', 'pos/cv781_5262.txt', 'pos/cv782_19526.txt',\n",
            " 'pos/cv783_13227.txt', 'pos/cv784_14394.txt', 'pos/cv785_22600.txt',\n",
            " 'pos/cv786_22497.txt', 'pos/cv787_13743.txt', 'pos/cv788_25272.txt',\n",
            " 'pos/cv789_12136.txt', 'pos/cv790_14600.txt', 'pos/cv791_16302.txt',\n",
            " 'pos/cv792_3832.txt', 'pos/cv793_13650.txt', 'pos/cv794_15868.txt',\n",
            " 'pos/cv795_10122.txt', 'pos/cv796_15782.txt', 'pos/cv797_6957.txt',\n",
            " 'pos/cv798_23531.txt', 'pos/cv799_18543.txt', 'pos/cv800_12368.txt',\n",
            " 'pos/cv801_25228.txt', 'pos/cv802_28664.txt', 'pos/cv803_8207.txt',\n",
            " 'pos/cv804_10862.txt', 'pos/cv805_19601.txt', 'pos/cv806_8842.txt',\n",
            " 'pos/cv807_21740.txt', 'pos/cv808_12635.txt', 'pos/cv809_5009.txt',\n",
            " 'pos/cv810_12458.txt', 'pos/cv811_21386.txt', 'pos/cv812_17924.txt',\n",
            " 'pos/cv813_6534.txt', 'pos/cv814_18975.txt', 'pos/cv815_22456.txt',\n",
            " 'pos/cv816_13655.txt', 'pos/cv817_4041.txt', 'pos/cv818_10211.txt',\n",
            " 'pos/cv819_9364.txt', 'pos/cv820_22892.txt', 'pos/cv821_29364.txt',\n",
            " 'pos/cv822_20049.txt', 'pos/cv823_15569.txt', 'pos/cv824_8838.txt',\n",
            " 'pos/cv825_5063.txt', 'pos/cv826_11834.txt', 'pos/cv827_18331.txt',\n",
            " 'pos/cv828_19831.txt', 'pos/cv829_20289.txt', 'pos/cv830_6014.txt',\n",
            " 'pos/cv831_14689.txt', 'pos/cv832_23275.txt', 'pos/cv833_11053.txt',\n",
            " 'pos/cv834_22195.txt', 'pos/cv835_19159.txt', 'pos/cv836_12968.txt',\n",
            " 'pos/cv837_27325.txt', 'pos/cv838_24728.txt', 'pos/cv839_21467.txt',\n",
            " 'pos/cv840_16321.txt', 'pos/cv841_3967.txt', 'pos/cv842_5866.txt',\n",
            " 'pos/cv843_15544.txt', 'pos/cv844_12690.txt', 'pos/cv845_14290.txt',\n",
            " 'pos/cv846_29497.txt', 'pos/cv847_1941.txt', 'pos/cv848_10036.txt',\n",
            " 'pos/cv849_15729.txt', 'pos/cv850_16466.txt', 'pos/cv851_20469.txt',\n",
            " 'pos/cv852_27523.txt', 'pos/cv853_29233.txt', 'pos/cv854_17740.txt',\n",
            " 'pos/cv855_20661.txt', 'pos/cv856_29013.txt', 'pos/cv857_15958.txt',\n",
            " 'pos/cv858_18819.txt', 'pos/cv859_14107.txt', 'pos/cv860_13853.txt',\n",
            " 'pos/cv861_1198.txt', 'pos/cv862_14324.txt', 'pos/cv863_7424.txt',\n",
            " 'pos/cv864_3416.txt', 'pos/cv865_2895.txt', 'pos/cv866_29691.txt',\n",
            " 'pos/cv867_16661.txt', 'pos/cv868_11948.txt', 'pos/cv869_23611.txt',\n",
            " 'pos/cv870_16348.txt', 'pos/cv871_24888.txt', 'pos/cv872_12591.txt',\n",
            " 'pos/cv873_18636.txt', 'pos/cv874_11236.txt', 'pos/cv875_5754.txt',\n",
            " 'pos/cv876_9390.txt', 'pos/cv877_29274.txt', 'pos/cv878_15694.txt',\n",
            " 'pos/cv879_14903.txt', 'pos/cv880_29800.txt', 'pos/cv881_13254.txt',\n",
            " 'pos/cv882_10026.txt', 'pos/cv883_27751.txt', 'pos/cv884_13632.txt',\n",
            " 'pos/cv885_12318.txt', 'pos/cv886_18177.txt', 'pos/cv887_5126.txt',\n",
            " 'pos/cv888_24435.txt', 'pos/cv889_21430.txt', 'pos/cv890_3977.txt',\n",
            " 'pos/cv891_6385.txt', 'pos/cv892_17576.txt', 'pos/cv893_26269.txt',\n",
            " 'pos/cv894_2068.txt', 'pos/cv895_21022.txt', 'pos/cv896_16071.txt',\n",
            " 'pos/cv897_10837.txt', 'pos/cv898_14187.txt', 'pos/cv899_16014.txt',\n",
            " 'pos/cv900_10331.txt', 'pos/cv901_11017.txt', 'pos/cv902_12256.txt',\n",
            " 'pos/cv903_17822.txt', 'pos/cv904_24353.txt', 'pos/cv905_29114.txt',\n",
            " 'pos/cv906_11491.txt', 'pos/cv907_3541.txt', 'pos/cv908_16009.txt',\n",
            " 'pos/cv909_9960.txt', 'pos/cv910_20488.txt', 'pos/cv911_20260.txt',\n",
            " 'pos/cv912_5674.txt', 'pos/cv913_29252.txt', 'pos/cv914_28742.txt',\n",
            " 'pos/cv915_8841.txt', 'pos/cv916_15467.txt', 'pos/cv917_29715.txt',\n",
            " 'pos/cv918_2693.txt', 'pos/cv919_16380.txt', 'pos/cv920_29622.txt',\n",
            " 'pos/cv921_12747.txt', 'pos/cv922_10073.txt', 'pos/cv923_11051.txt',\n",
            " 'pos/cv924_29540.txt', 'pos/cv925_8969.txt', 'pos/cv926_17059.txt',\n",
            " 'pos/cv927_10681.txt', 'pos/cv928_9168.txt', 'pos/cv929_16908.txt',\n",
            " 'pos/cv930_13475.txt', 'pos/cv931_17563.txt', 'pos/cv932_13401.txt',\n",
            " 'pos/cv933_23776.txt', 'pos/cv934_19027.txt', 'pos/cv935_23841.txt',\n",
            " 'pos/cv936_15954.txt', 'pos/cv937_9811.txt', 'pos/cv938_10220.txt',\n",
            " 'pos/cv939_10583.txt', 'pos/cv940_17705.txt', 'pos/cv941_10246.txt',\n",
            " 'pos/cv942_17082.txt', 'pos/cv943_22488.txt', 'pos/cv944_13521.txt',\n",
            " 'pos/cv945_12160.txt', 'pos/cv946_18658.txt', 'pos/cv947_10601.txt',\n",
            " 'pos/cv948_24606.txt', 'pos/cv949_20112.txt', 'pos/cv950_12350.txt',\n",
            " 'pos/cv951_10926.txt', 'pos/cv952_25240.txt', 'pos/cv953_6836.txt',\n",
            " 'pos/cv954_18628.txt', 'pos/cv955_25001.txt', 'pos/cv956_11609.txt',\n",
            " 'pos/cv957_8737.txt', 'pos/cv958_12162.txt', 'pos/cv959_14611.txt',\n",
            " 'pos/cv960_29007.txt', 'pos/cv961_5682.txt', 'pos/cv962_9803.txt',\n",
            " 'pos/cv963_6895.txt', 'pos/cv964_6021.txt', 'pos/cv965_26071.txt',\n",
            " 'pos/cv966_28832.txt', 'pos/cv967_5788.txt', 'pos/cv968_24218.txt',\n",
            " 'pos/cv969_13250.txt', 'pos/cv970_18450.txt', 'pos/cv971_10874.txt',\n",
            " 'pos/cv972_26417.txt', 'pos/cv973_10066.txt', 'pos/cv974_22941.txt',\n",
            " 'pos/cv975_10981.txt', 'pos/cv976_10267.txt', 'pos/cv977_4938.txt',\n",
            " 'pos/cv978_20929.txt', 'pos/cv979_18921.txt', 'pos/cv980_10953.txt',\n",
            " 'pos/cv981_14989.txt', 'pos/cv982_21103.txt', 'pos/cv983_22928.txt',\n",
            " 'pos/cv984_12767.txt', 'pos/cv985_6359.txt', 'pos/cv986_13527.txt',\n",
            " 'pos/cv987_6965.txt', 'pos/cv988_18740.txt', 'pos/cv989_15824.txt',\n",
            " 'pos/cv990_11591.txt', 'pos/cv991_18645.txt', 'pos/cv992_11962.txt',\n",
            " 'pos/cv993_29737.txt', 'pos/cv994_12270.txt', 'pos/cv995_21821.txt',\n",
            " 'pos/cv996_11592.txt', 'pos/cv997_5046.txt', 'pos/cv998_14111.txt',\n",
            " 'pos/cv999_13106.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "all_review_ids = positive_review_ids + negative_review_ids"
      ],
      "metadata": {
        "id": "i1xXz1FbB0aw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "def is_positive(review_id):\n",
        "  \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
        "  text = nltk.corpus.movie_reviews.raw(review_id)\n",
        "  scores = [sia.polarity_scores(sentence)[\"compound\"] for sentence in nltk.sent_tokenize(text)]\n",
        "  return mean(scores) > 0\n",
        "\n",
        "shuffle(all_review_ids)\n",
        "correct = 0\n",
        "for review_id in all_review_ids:\n",
        "  if is_positive(review_id):\n",
        "    if review_id in positive_review_ids:\n",
        "      correct += 1\n",
        "    else:\n",
        "      if review_id in negative_review_ids:\n",
        "        correct += 1\n",
        "\n",
        "print(F\"{correct / len(all_review_ids):.2%} correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMOEVj-0B_u4",
        "outputId": "ae340cfc-f344-4057-8a9b-93074db03db6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69.15% correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing NLTK’s Sentiment Analysis"
      ],
      "metadata": {
        "id": "_GsmJoN3DI_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
        "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
        "\n",
        "def skip_unwanted(pos_tuple):\n",
        "    word, tag = pos_tuple\n",
        "    if not word.isalpha() or word in unwanted:\n",
        "        return False\n",
        "    if tag.startswith(\"NN\"):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "positive_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
        ")]\n",
        "negative_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
        ")]"
      ],
      "metadata": {
        "id": "m--1EMjLEMQy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, you also add words from the names corpus to the unwanted list on line 2 since movie reviews are likely to have lots of actor names, which shouldn’t be part of your feature sets."
      ],
      "metadata": {
        "id": "s8ps6wlZHxix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
        "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
        "\n",
        "def skip_unwanted(pos_tuple):\n",
        "    word, tag = pos_tuple\n",
        "    if not word.isalpha() or word in unwanted:\n",
        "        return False\n",
        "    if tag.startswith(\"NN\"):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "positive_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
        ")]\n",
        "negative_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
        ")]"
      ],
      "metadata": {
        "id": "Yfte-pwNEMMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_fd = nltk.FreqDist(positive_words)\n",
        "negative_fd = nltk.FreqDist(negative_words)\n",
        "\n",
        "common_set = set(positive_fd).intersection(negative_fd)\n",
        "\n",
        "for word in common_set:\n",
        "  del positive_fd[word]\n",
        "  del negative_fd[word]\n",
        "\n",
        "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
        "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
      ],
      "metadata": {
        "id": "7tL01iOtINXF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(top_100_positive, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-DI7MiKI9rc",
        "outputId": "78127af6-01e0-4e0c-ad98-f3bdbd542975"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'addresses', 'amistad', 'apostle', 'argento', 'attentive', 'audacious',\n",
            " 'balancing', 'belgian', 'benefit', 'biased', 'brisk', 'broadcast', 'claiborne',\n",
            " 'conveys', 'criticized', 'curdled', 'danish', 'deft', 'deftly', 'donkey',\n",
            " 'elegantly', 'embeth', 'en', 'exhilarating', 'fa', 'falter', 'farquaad', 'fei',\n",
            " 'flynt', 'forceful', 'freed', 'funnest', 'galactic', 'ghost', 'hanks',\n",
            " 'horned', 'indistinguishable', 'jedi', 'kimble', 'kudos', 'legally',\n",
            " 'lovingly', 'lumumba', 'masterfully', 'matches', 'maximus', 'melancholy',\n",
            " 'methodical', 'monetary', 'motta', 'mulan', 'narrates', 'nello', 'niccol',\n",
            " 'notoriously', 'ordell', 'organizing', 'perceived', 'pink', 'powerfully',\n",
            " 'profile', 'propelled', 'pun', 'radio', 'redefines', 'rico', 'safely',\n",
            " 'seahaven', 'shanghai', 'shrek', 'sobbing', 'societal', 'soviet', 'spacey',\n",
            " 'sparks', 'stendhal', 'superficially', 'supreme', 'sweetback', 'tale',\n",
            " 'taxing', 'textured', 'tibbs', 'tibetan', 'trimmed', 'ulee', 'unassuming',\n",
            " 'uncompromising', 'uncut', 'understatement', 'unnerving', 'unquestionably',\n",
            " 'unrestrained', 'unzipped', 'valjean', 'vertical', 'vividly', 'watson',\n",
            " 'weaves', 'weir'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(top_100_negative, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqCaK3rSI9ke",
        "outputId": "8ebc6024-5b76-4621-8231-e941e7e7d619"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'abysmal', 'amish', 'artemus', 'audible', 'autistic', 'babe', 'battlefield',\n",
            " 'bean', 'brazilian', 'brenner', 'busted', 'chi', 'chuckled', 'club', 'comment',\n",
            " 'consecutive', 'crucible', 'deems', 'degenerates', 'digested', 'disguise',\n",
            " 'droppingly', 'ego', 'embarassing', 'enticing', 'favors', 'fetch', 'flipped',\n",
            " 'flubber', 'forgetful', 'geronimo', 'glancing', 'godzilla', 'goo', 'gordy',\n",
            " 'grunting', 'harlem', 'heckerling', 'horrid', 'iii', 'incoherent', 'injury',\n",
            " 'interspersed', 'jericho', 'joely', 'lamest', 'leaden', 'leguizamo',\n",
            " 'manchurian', 'mandingo', 'modeled', 'monumentally', 'mumbo', 'mystery',\n",
            " 'nbsp', 'negated', 'nitro', 'ordering', 'pad', 'pathetically', 'performances',\n",
            " 'peripheral', 'plodding', 'popped', 'potty', 'precinct', 'psychlo', 'putrid',\n",
            " 'rabid', 'rambo', 'rotating', 'sans', 'schumacher', 'segal', 'sneering',\n",
            " 'snipes', 'spawn', 'sphere', 'squabble', 'stalks', 'stinks', 'stupidest',\n",
            " 'stupidly', 'supergirl', 'tearing', 'tectonic', 'tediously', 'terminal',\n",
            " 'topless', 'traced', 'undercut', 'undeveloped', 'unentertaining', 'unhealthy',\n",
            " 'verhoven', 'virus', 'warranted', 'wcw', 'weighed', 'wisecracking'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s how you can set up the positive and negative bigram finders:"
      ],
      "metadata": {
        "id": "J7n2Zym5JTPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
        "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
        "\n",
        "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
        "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
        "    if w.isalpha() and w not in unwanted\n",
        "])\n",
        "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
        "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
        "    if w.isalpha() and w not in unwanted\n",
        "])"
      ],
      "metadata": {
        "id": "xi-qv-CiJS33"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Using a Classifier"
      ],
      "metadata": {
        "id": "TZNkkSvhJnZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be continued."
      ],
      "metadata": {
        "id": "gwb7wp2aKV6C"
      }
    }
  ]
}